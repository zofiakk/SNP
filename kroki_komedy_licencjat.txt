To jest plik z kolejnymi krokami które robiłam na paired-end surowych danych z RNA-seq razem z dupnymi skryptami których używałam
Zakładam że przyda nam się do projektu

1. Mapowanie- Hisat:

for f in `ls -1 /home/zkochanska/link1/*_1.fastq.gz | sed 's/_1.fastq.gz//' ` 
do
echo ${f}
hisat2 -q -p 12 -x /home/zkochanska/reference/grch38_tran/genome_tran -1 ${f}_1.fastq.gz -2 ${f}_2.fastq.gz -S /home/zkochanska/link1_hisat/${f:23}.bam --summary-file ${f:23}.txt -t
done


2. Oznaczanie duplikatów: (Picard Tools)
-> Sortowanie:

FILES="/home/zkochanska/link1_hisat/*.bam"
for f in $FILES 
do
echo ${f}
java -jar /home/zkochanska/picard/picard.jar SortSam INPUT=${f} OUTPUT= /home/zkochanska/link1_sortsam/${f:29:10}_sorted.bam SORT_ORDER=coordinate
done

-> Read groups: (To trzeba koniecznie zminić bo to jest przyczyna pewnych błędów później)

FILES="/home/zkochanska/link1_hisat/*.bam"
for f in $FILES 
do
echo ${f}
java -jar /home/zkochanska/picard/picard.jar AddOrReplaceReadGroups -I /home/zkochanska/link1_sortsam/${f:29:10}_sorted.bam -O /home/zkochanska/link1_addread/${f:29:10}_sorted_add.bam -SORT_ORDER coordinate -RGID Label -RGLB Label -RGPL illumina --RGPU Label --RGSM Label 
done

Zamiast Label powinno isę jednak wpisać mądre rzeczy: (wytłumaczenie http://galaxy.med.tufts.edu/tool_runner?tool_id=picard_ARRG)
Pewnie fajnie byłoby dodoać info o tym czy to jest kontrola czy nie 
RGID-
RGPL- platforma na której sie sekwencjonowało (np illumina, solid, 454, pacbio, helicos)
RGSM- SAmple name
RGLB- group library


-> Duplikaty

FILES="/home/zkochanska/link1_sortsam/*sorted.bam"
for f in $FILES 
do
echo ${f}
java -jar /home/zkochanska/picard/picard.jar MarkDuplicates -INPUT /home/zkochanska/link1_addread/${f:31:10}_sorted_add.bam -OUTPUT /home/zkochanska/link1_dupli/${f:31:10}_sorted_add_dedup.bam -M /home/zkochanska/link1_dupli/${f:31:10}_metrics.txt -CREATE_INDEX true
done

-> reorder:

FILES="/home/zkochanska/link1_addread/*sorted_add.bam"
for f in $FILES 
do
echo ${f}
java -jar /home/zkochanska/picard/picard.jar ReorderSam -INPUT /home/zkochanska/link1_dupli/${f:31:10}_sorted_add_dedup.bam -OUTPUT /home/zkochanska/link1_reorder/${f:31:10}_reorder.bam -SD /home/zkochanska/reference/grch38_tran/genome.fa -CREATE_INDEX true
done


3. Modyfikacja odczytów:

#!/bin/sh
FILES="/home/zkochanska/link1_dupli/*sorted_add_dedup.bam"
for f in $FILES 
do
echo ${f}
java -Xmx20G -XX:+UseParallelGC -XX:ParallelGCThreads=20 -jar /home/norbert/local/gatk/build/libs/gatk.jar SplitNCigarReads -R /home/zkochanska/reference/grch38_tran/genome.fa -I /home/zkochanska/link1_reorder/${f:29:10}_reorder.bam -O /home/zkochanska/link1_cigar/${f:29:10}_split.bam
done


4. Szukanie wariantów

#!/bin/sh
FILES="/home/zkochanska/link1_hisat/*.bam"
for f in $FILES 
do
echo ${f}
python /home/norbert/local/gatk/gatk --java-options "-Xmx20G -XX:+UseParallelGC -XX:ParallelGCThreads=5" HaplotypeCaller -R /home/zkochanska/reference/grch38_tran/genome.fa -I /home/zkochanska/link1_cigar/${f:29:10}_split.bam -O /home/zkochanska/link1_haplotype/${f:29:10}.vcf --native-pair-hmm-threads 10   
done


5. WYbór wariantów do analizy

-> Wybór SNP:
#!/bin/sh
FILES="/home/zkochanska/link1_hisat/*.bam"
for f in $FILES 
do
echo ${f}
python /home/norbert/local/gatk/gatk SelectVariants -R /home/zkochanska/reference/grch38_tran/genome.fa -O /home/zkochanska/link1_select/${f:29:10}_snp.vcf -V /home/zkochanska/link1_haplotype/${f:29:10}.vcf --select-type-to-include SNP

done 

-> Wybór INDEL
#!/bin/sh
FILES="/home/zkochanska/link1_hisat/*.bam"
for f in $FILES 
do
echo ${f}
python /home/norbert/local/gatk/gatk SelectVariants -R /home/zkochanska/reference/grch38_tran/genome.fa -O /home/zkochanska/link1_select/${f:29:10}_ind.vcf -V /home/zkochanska/link1_haplotype/${f:29:10}.vcf  --select-type-to-include INDEL 
done 

-> Do obu trzeba dodoac indeksy (może lepiej to włączyć do wyszukiwania)
#!/bin/sh
FILES="/home/zkochanska/link1_select/*_2.vcf.gz"
for f in $FILES 
do
echo ${f}
tabix -p vcf ${f:30}
done 

-> We wcześniejszych krokach miałam błędy więc musiałam zminiac head: (Postaram się przypomnieć gdzie to było i zmienić w tym pliku)
#!/bin/sh
FILES="/home/zkochanska/link1/link1_hisat/*.bam"
for f in $FILES 
do
echo ${f:35:10}
bcftools  reheader -s ${f:35:10}.txt -o ${f:35:10}_ind_2.vcf ${f:35:10}_ind.vcf
done 


6. Konsolidacja wyników (łączenie danych o SNP i Indel z oddzielnych plików dla próbek w pliki dla typów wariacji)

bGzip -c plik > plik
tabix -p vcf
bcftools merge -l pliki_snp_cont.list -o link2_oba.vcf -O v



7. Filtrowanie wariantów:

-> INDELE
python /home/norbert/local/gatk/gatk VariantFiltration -R /home/zkochanska/reference/grch38_tran/genome.fa -V /home/zkochanska/link1_select/link1_ind.vcf -O /home/zkochanska/link1_filter/link1_ind_filtered.vcf.gz \
-filter "QD < 5.0" --filter-name "QD5" \
    -filter "QUAL < 35.0" --filter-name "QUAL35" \
    -filter "FS > 75.0" --filter-name "FS75" \
    -filter "ReadPosRankSum < -10.0" --filter-name "ReadPosRankSum-10" \
	-filter "DP < 10.0" --filter-name "Coverage10" 
	
-> SNP:

python /home/norbert/local/gatk/gatk VariantFiltration -R /home/zkochanska/reference/grch38_tran/genome.fa -V /home/zkochanska/link1_select/link1_snp.vcf -O /home/zkochanska/link1_filter/link1_snp_filtered.vcf.gz \
-filter "QD < 5.0" --filter-name "QD5" \
    -filter "QUAL < 35.0" --filter-name "QUAL35" \
    -filter "SOR > 2.5" --filter-name "SOR25" \
    -filter "FS > 50.0" --filter-name "FS50" \
    -filter "MQ < 55.0" --filter-name "MQ55" \
    -filter "MQRankSum < -12.5" --filter-name "MQRankSum-12.5" \
    -filter "ReadPosRankSum < -8.0" --filter-name "ReadPosRankSum-8" \
	-filter "DP < 10" --filter-name "Coverage10"


8. Konsolidacja wariantów (SNP + INDEL)

java -jar /home/zkochanska/picard/picard.jar MergeVcfs -I link2_cont_filtered_combined2.vcf -I link2_filtered_combined2.vcf -O link2_oba

9. Adnotacja wariantów:

10. Ocena wariantów




